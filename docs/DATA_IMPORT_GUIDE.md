# üì• Guia de Importa√ß√£o de Dados - ProfitChart CSV

**√öltima Atualiza√ß√£o:** 28 de Janeiro de 2026  
**Status:** ‚úÖ 775.259 registros importados com sucesso

---

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Localiza√ß√£o dos Arquivos](#localiza√ß√£o-dos-arquivos)
3. [Formatos CSV](#formatos-csv)
4. [Banco de Dados](#banco-de-dados)
5. [Scripts de Importa√ß√£o](#scripts-de-importa√ß√£o)
6. [Procedimento de Importa√ß√£o](#procedimento-de-importa√ß√£o)
7. [Valida√ß√£o](#valida√ß√£o)
8. [Troubleshooting](#troubleshooting)
9. [Hist√≥rico de Importa√ß√µes](#hist√≥rico-de-importa√ß√µes)

---

## üéØ Vis√£o Geral

Este documento descreve o processo completo de importa√ß√£o de dados hist√≥ricos do ProfitChart para o sistema B3 Trading Platform.

**Estat√≠sticas Atuais:**
- **Total de registros:** 775.259
- **S√≠mbolos √∫nicos:** 58
- **Per√≠odo coberto:** Janeiro/2023 ‚Üí Janeiro/2026 (3 anos)
- **Timeframes:** 15min, 60min, Di√°rio
- **Taxa de sucesso:** 100%

---

## üìÇ Localiza√ß√£o dos Arquivos

### Pasta Principal

```
/home/dellno/√Årea de trabalho/dadoshistoricos.csv/
‚îú‚îÄ‚îÄ dados23e24/          # Hist√≥rico 2023-2025
‚îÇ   ‚îú‚îÄ‚îÄ PETR4_B_0_15min.csv
‚îÇ   ‚îú‚îÄ‚îÄ PETR4_B_0_60min.csv
‚îÇ   ‚îú‚îÄ‚îÄ PETR4_B_0_Di√°rio.csv
‚îÇ   ‚îú‚îÄ‚îÄ VALE3_B_0_15min.csv
‚îÇ   ‚îî‚îÄ‚îÄ ... (157 arquivos totais)
‚îÇ
‚îî‚îÄ‚îÄ dados26/             # Janeiro 2026
    ‚îú‚îÄ‚îÄ PETR4_B_0_15min.csv
    ‚îú‚îÄ‚îÄ PETR4_B_0_60min.csv
    ‚îú‚îÄ‚îÄ PETR4_B_0_Di√°rio.csv
    ‚îî‚îÄ‚îÄ ... (72 arquivos totais)
```

### Nomenclatura dos Arquivos

**Padr√£o:** `{SYMBOL}_B_0_{TIMEFRAME}.csv`

Onde:
- `{SYMBOL}`: C√≥digo do ativo (ex: PETR4, VALE3)
- `B`: Fonte (ProfitChart B3)
- `0`: Vers√£o do arquivo
- `{TIMEFRAME}`: 15min, 60min ou Di√°rio

**Exemplos:**
- `PETR4_B_0_15min.csv` - Petrobras PN, 15 minutos
- `VALE3_B_0_60min.csv` - Vale ON, 60 minutos
- `ITUB4_B_0_Di√°rio.csv` - Ita√∫ Unibanco PN, di√°rio

---

## üìä Formatos CSV

### ‚ö†Ô∏è ATEN√á√ÉO: Formatos Diferentes!

O ProfitChart exporta arquivos com **formatos diferentes** dependendo do timeframe:

### Formato Intraday (15min, 60min)

**Colunas:** 9 campos separados por `;`

```csv
symbol;date;time;open;high;low;close;volume_brl;volume_qty
PETR4;30/12/2024;17:00:00;32,83;32,97;32,80;32,80;215181183,90;6552300
PETR4;30/12/2024;16:00:00;32,86;32,90;32,75;32,83;189234567,80;5789123
PETR4;30/12/2024;15:00:00;32,90;33,05;32,85;32,86;156789234,50;4789234
```

**Descri√ß√£o dos Campos:**

| Campo | Tipo | Formato | Descri√ß√£o | Exemplo |
|-------|------|---------|-----------|---------|
| symbol | String | - | C√≥digo do ativo | PETR4 |
| date | String | DD/MM/YYYY | Data da cota√ß√£o | 30/12/2024 |
| **time** | String | HH:MM:SS | **Hor√°rio da cota√ß√£o** | 17:00:00 |
| open | Float | V√≠rgula | Pre√ßo de abertura | 32,83 |
| high | Float | V√≠rgula | Pre√ßo m√°ximo | 32,97 |
| low | Float | V√≠rgula | Pre√ßo m√≠nimo | 32,80 |
| close | Float | V√≠rgula | Pre√ßo de fechamento | 32,80 |
| volume_brl | Float | V√≠rgula | Volume financeiro (R$) | 215181183,90 |
| volume_qty | Integer | - | Quantidade negociada | 6552300 |

### Formato Di√°rio

**Colunas:** 8 campos separados por `;` (SEM campo `time`)

```csv
symbol;date;open;high;low;close;volume_brl;volume_qty
PETR4;30/12/2024;32,43;32,97;32,42;32,80;733138158,20;22355600
PETR4;27/12/2024;32,63;32,63;32,28;32,33;784245347,60;24167200
PETR4;26/12/2024;32,30;32,63;32,27;32,42;743936420,70;22920700
```

**Descri√ß√£o dos Campos:**

| Campo | Tipo | Formato | Descri√ß√£o | Exemplo |
|-------|------|---------|-----------|---------|
| symbol | String | - | C√≥digo do ativo | PETR4 |
| date | String | DD/MM/YYYY | Data da cota√ß√£o | 30/12/2024 |
| open | Float | V√≠rgula | Pre√ßo de abertura | 32,43 |
| high | Float | V√≠rgula | Pre√ßo m√°ximo | 32,97 |
| low | Float | V√≠rgula | Pre√ßo m√≠nimo | 32,42 |
| close | Float | V√≠rgula | Pre√ßo de fechamento | 32,80 |
| volume_brl | Float | V√≠rgula | Volume financeiro (R$) | 733138158,20 |
| volume_qty | Integer | - | Quantidade negociada | 22355600 |

### üîë Diferen√ßa Cr√≠tica

```
üìå INTRADAY: symbol;date;TIME;open;high;low;close;volume_brl;volume_qty  (9 campos)
üìå DI√ÅRIO:   symbol;date;open;high;low;close;volume_brl;volume_qty       (8 campos)
```

**NUNCA confundir os formatos!** O parser precisa detectar o timeframe e usar o parser correto.

---

## üóÑÔ∏è Banco de Dados

### TimescaleDB

**Conex√£o:**
- Host: `b3-timescaledb` (via Docker network)
- Porta: `5432` (interna) / `5433` (host)
- Database: `b3trading_market`
- Usu√°rio: `b3trading_ts`
- Password: `b3trading_ts_pass`

### Hypertables

#### 1. ohlcv_15min

**Descri√ß√£o:** Dados de 15 minutos

```sql
CREATE TABLE ohlcv_15min (
    symbol VARCHAR(10) NOT NULL,
    time TIMESTAMPTZ NOT NULL,
    open DOUBLE PRECISION NOT NULL,
    high DOUBLE PRECISION NOT NULL,
    low DOUBLE PRECISION NOT NULL,
    close DOUBLE PRECISION NOT NULL,
    volume BIGINT NOT NULL,
    PRIMARY KEY (symbol, time)
);

SELECT create_hypertable('ohlcv_15min', 'time', chunk_time_interval => INTERVAL '7 days');
```

**Estat√≠sticas:**
- Registros: ~338.847 (28/01/2026)
- Particionamento: Chunks de 7 dias
- S√≠mbolos: 42 (nem todos t√™m dados 15min)

#### 2. ohlcv_60min

**Descri√ß√£o:** Dados de 60 minutos (1 hora)

```sql
CREATE TABLE ohlcv_60min (
    symbol VARCHAR(10) NOT NULL,
    time TIMESTAMPTZ NOT NULL,
    open DOUBLE PRECISION NOT NULL,
    high DOUBLE PRECISION NOT NULL,
    low DOUBLE PRECISION NOT NULL,
    close DOUBLE PRECISION NOT NULL,
    volume BIGINT NOT NULL,
    PRIMARY KEY (symbol, time)
);

SELECT create_hypertable('ohlcv_60min', 'time', chunk_time_interval => INTERVAL '30 days');
```

**Estat√≠sticas:**
- Registros: ~407.470 (28/01/2026)
- Particionamento: Chunks de 30 dias
- S√≠mbolos: 57 (quase todos t√™m dados 60min)

#### 3. ohlcv_daily

**Descri√ß√£o:** Dados di√°rios

```sql
CREATE TABLE ohlcv_daily (
    symbol VARCHAR(10) NOT NULL,
    time TIMESTAMPTZ NOT NULL,
    open DOUBLE PRECISION NOT NULL,
    high DOUBLE PRECISION NOT NULL,
    low DOUBLE PRECISION NOT NULL,
    close DOUBLE PRECISION NOT NULL,
    volume BIGINT NOT NULL,
    PRIMARY KEY (symbol, time)
);

SELECT create_hypertable('ohlcv_daily', 'time', chunk_time_interval => INTERVAL '365 days');
```

**Estat√≠sticas:**
- Registros: ~28.942 (28/01/2026)
- Particionamento: Chunks de 365 dias
- S√≠mbolos: 58 (todos t√™m dados di√°rios)

---

## üîß Scripts de Importa√ß√£o

### Script Principal

**Localiza√ß√£o:** `scripts/import_historical_data.py`

**Linguagem:** Python 3.11+

**Depend√™ncias:**
```python
asyncpg==0.29.0    # PostgreSQL async driver
loguru==0.7.2      # Structured logging
```

### Arquitetura do Script

```python
class HistoricalDataImporter:
    """Importador de dados hist√≥ricos para TimescaleDB"""
    
    def __init__(self):
        self.pool = None  # asyncpg connection pool
        self.stats = {...}  # Estat√≠sticas de importa√ß√£o
    
    async def connect(self):
        """Conecta ao TimescaleDB"""
    
    def parse_csv_line(self, line: list, is_daily: bool = False) -> dict:
        """
        Parse condicional:
        - is_daily=True: 8 campos (sem time)
        - is_daily=False: 9 campos (com time)
        """
    
    async def import_file(self, file_path: Path, phase: str):
        """Importa um arquivo CSV usando COPY"""
    
    async def import_symbol(self, symbol: str, folder: Path, phase: str):
        """Importa todos os timeframes de um s√≠mbolo"""
    
    async def import_priority_symbols(self):
        """Fase 1: Importa 5 s√≠mbolos priorit√°rios"""
    
    async def import_remaining_symbols(self):
        """Fase 2: Importa 53 s√≠mbolos restantes"""
    
    async def validate_import(self, symbols: list):
        """Valida importa√ß√£o mostrando estat√≠sticas"""
```

### Funcionalidades Principais

1. **Parse Condicional**
   - Detecta se √© arquivo Di√°rio (8 campos) ou Intraday (9 campos)
   - Usa parser apropriado para cada tipo

2. **Bulk Insert via COPY**
   - Performance otimizada: ~28.000 registros/segundo
   - Mais r√°pido que INSERT VALUES

3. **Valida√ß√£o de Duplicatas**
   - Verifica se dados j√° existem no per√≠odo
   - Oferece op√ß√£o de remover e reimportar

4. **Logging Estruturado**
   - Estat√≠sticas em tempo real
   - Erros detalhados com context

5. **Execu√ß√£o em Fases**
   - Fase 1: 5 priorit√°rios (PETR4, VALE3, ITUB4, BBDC4, ABEV3)
   - Fase 2: 53 restantes (opcional)

---

## üöÄ Procedimento de Importa√ß√£o

### Pr√©-requisitos

1. **Container TimescaleDB rodando:**
```bash
docker ps | grep b3-timescaledb
# Deve retornar uma linha com status "Up"
```

2. **Arquivos CSV dispon√≠veis:**
```bash
ls -l "/home/dellno/√Årea de trabalho/dadoshistoricos.csv/dados23e24/" | wc -l
# Deve retornar 157+ (incluindo diret√≥rio)
```

3. **Rede Docker dispon√≠vel:**
```bash
docker network ls | grep b3-trading-platform_b3-network
# Deve retornar uma linha
```

### Backup (Recomendado)

Antes de importar, fazer backup do banco:

```bash
docker exec b3-timescaledb pg_dump -U b3trading_ts b3trading_market > backup_$(date +%Y%m%d).sql
```

### Execu√ß√£o

**Comando Completo:**

```bash
docker run --rm -it \
  -v "/home/dellno/√Årea de trabalho/dadoshistoricos.csv:/data" \
  -v /home/dellno/worksapace/b3-trading-platform/scripts:/scripts \
  --network b3-trading-platform_b3-network \
  python:3.11-slim bash -c "pip install -q asyncpg loguru && python3 /scripts/import_historical_data.py"
```

**Explica√ß√£o dos Par√¢metros:**

- `--rm`: Remove container ap√≥s execu√ß√£o
- `-it`: Modo interativo (permite input do usu√°rio)
- `-v "...:/data"`: Monta pasta de dados como `/data` no container
- `-v .../scripts:/scripts`: Monta pasta de scripts
- `--network`: Conecta √† rede Docker do projeto
- `pip install -q`: Instala depend√™ncias silenciosamente
- `python3 /scripts/...`: Executa script de importa√ß√£o

### Fluxo de Execu√ß√£o

1. **Conex√£o ao Banco:**
   ```
   Conectando ao TimescaleDB: b3-timescaledb:5432
   ‚úÖ Conex√£o estabelecida!
   ```

2. **Fase 1 - Priorit√°rios:**
   ```
   üéØ FASE 1: ATIVOS PRIORIT√ÅRIOS (5 s√≠mbolos)
   S√≠mbolos: PETR4, VALE3, ITUB4, BBDC4, ABEV3
   Pasta: dados23e24 (2023-2025)
   
   üìä PETR4
     ‚úÖ 1,888 registros importados (15min)
     ‚úÖ 3,994 registros importados (60min)
     ‚úÖ 499 registros importados (Di√°rio)
   
   [... continua para outros 4 s√≠mbolos]
   ```

3. **Valida√ß√£o Fase 1:**
   ```
   ‚úÖ VALIDA√á√ÉO DA IMPORTA√á√ÉO
   
   üìä PETR4:
     15min: 2,498 candles | 2024-09-30 ‚Üí 2026-01-28
     60min: 4,150 candles | 2023-01-02 ‚Üí 2026-01-28
     Di√°rio: 499 candles | 2023-01-02 ‚Üí 2024-12-30
   ```

4. **Prompt Fase 2:**
   ```
   üîÑ Deseja continuar com a FASE 2 (53 s√≠mbolos restantes)? (s/N):
   ```
   - Digitar `s` para continuar
   - Digitar `n` para cancelar

5. **Fase 2 - Restantes:**
   ```
   üìà FASE 2: S√çMBOLOS RESTANTES (53 s√≠mbolos)
   
   üìä AZUL4
     ‚úÖ 3,994 registros importados (60min)
     ‚úÖ 499 registros importados (Di√°rio)
   
   [... continua para outros 52 s√≠mbolos]
   ```

6. **Estat√≠sticas Finais:**
   ```
   üìä ESTAT√çSTICAS FINAIS
   
   Priorit√°rios:
     Arquivos: 15
     Registros: 62,674
     Erros: 0
   
   Restantes:
     Arquivos: 142
     Registros: 712,585
     Erros: 0
   
   TOTAL:
     Arquivos: 157
     Registros: 775,259
     Erros: 0
   
   üéâ Importa√ß√£o conclu√≠da com sucesso!
   ```

---

## ‚úÖ Valida√ß√£o

### Queries de Valida√ß√£o

#### 1. Total de Registros por Tabela

```sql
SELECT 'ohlcv_15min' as tabela, COUNT(*) as total 
FROM ohlcv_15min
UNION ALL
SELECT 'ohlcv_60min', COUNT(*) 
FROM ohlcv_60min
UNION ALL
SELECT 'ohlcv_daily', COUNT(*) 
FROM ohlcv_daily;
```

**Resultado Esperado (28/01/2026):**
```
tabela         | total
---------------|--------
ohlcv_15min    | 338847
ohlcv_60min    | 407470
ohlcv_daily    |  28942
```

#### 2. Cobertura dos Priorit√°rios

```sql
SELECT 
    symbol,
    COUNT(*) as candles,
    MIN(time) as primeiro,
    MAX(time) as ultimo,
    MAX(time) - MIN(time) as periodo_dias
FROM ohlcv_daily
WHERE symbol IN ('PETR4', 'VALE3', 'ITUB4', 'BBDC4', 'ABEV3')
GROUP BY symbol
ORDER BY symbol;
```

**Resultado Esperado:**
```
symbol | candles | primeiro   | ultimo     | periodo_dias
-------|---------|------------|------------|-------------
ABEV3  | 499     | 2023-01-02 | 2024-12-30 | 728 days
BBDC4  | 499     | 2023-01-02 | 2024-12-30 | 728 days
ITUB4  | 499     | 2023-01-02 | 2024-12-30 | 728 days
PETR4  | 499     | 2023-01-02 | 2024-12-30 | 728 days
VALE3  | 499     | 2023-01-02 | 2024-12-30 | 728 days
```

#### 3. S√≠mbolos com Dados Intraday

```sql
-- S√≠mbolos com dados 15min
SELECT symbol, COUNT(*) as candles_15min
FROM ohlcv_15min
GROUP BY symbol
ORDER BY candles_15min DESC
LIMIT 10;

-- S√≠mbolos com dados 60min
SELECT symbol, COUNT(*) as candles_60min
FROM ohlcv_60min
GROUP BY symbol
ORDER BY candles_60min DESC
LIMIT 10;
```

#### 4. Verificar Gaps de Dados

```sql
-- Verificar se h√° gaps maiores que 7 dias (para 60min)
WITH gaps AS (
    SELECT 
        symbol,
        time,
        LAG(time) OVER (PARTITION BY symbol ORDER BY time) as prev_time,
        time - LAG(time) OVER (PARTITION BY symbol ORDER BY time) as gap
    FROM ohlcv_60min
    WHERE symbol = 'PETR4'
)
SELECT * FROM gaps
WHERE gap > INTERVAL '7 days'
ORDER BY time;
```

#### 5. Validar OHLC (Pre√ßos)

```sql
-- Verificar se high >= close >= low (regra OHLC)
SELECT 
    symbol,
    time,
    open, high, low, close
FROM ohlcv_daily
WHERE NOT (high >= close AND close >= low AND high >= open AND open >= low)
LIMIT 10;

-- Resultado esperado: 0 registros (todos devem ser v√°lidos)
```

---

## üêõ Troubleshooting

### Problema 1: "Pasta n√£o encontrada"

**Erro:**
```
‚ùå Pasta n√£o encontrada: /home/dellno/√Årea de trabalho/dadoshistoricos.csv/dados23e24
```

**Causas Poss√≠veis:**
1. Path incorreto (verificar espa√ßos, acentua√ß√£o)
2. Volume mount n√£o configurado
3. Pasta vazia ou sem permiss√µes

**Solu√ß√£o:**
```bash
# Verificar se pasta existe
ls -la "/home/dellno/√Årea de trabalho/dadoshistoricos.csv/dados23e24/"

# Verificar permiss√µes
chmod -R 755 "/home/dellno/√Årea de trabalho/dadoshistoricos.csv/"

# Verificar volume mount no comando docker run
# Deve ter: -v "/home/dellno/√Årea de trabalho/dadoshistoricos.csv:/data"
```

### Problema 2: "Nenhum registro v√°lido"

**Erro:**
```
‚ö†Ô∏è Nenhum registro v√°lido encontrado
```

**Causas Poss√≠veis:**
1. Formato CSV incorreto
2. Parser esperando 9 colunas mas arquivo tem 8 (Di√°rio)
3. Encoding do arquivo incorreto

**Solu√ß√£o:**
```bash
# Verificar formato do arquivo
head -3 PETR4_B_0_Di√°rio.csv

# Contar colunas (deve ser 8 para Di√°rio, 9 para Intraday)
head -1 PETR4_B_0_Di√°rio.csv | awk -F';' '{print NF}'

# Verificar encoding
file -i PETR4_B_0_Di√°rio.csv
```

### Problema 3: "Connection refused"

**Erro:**
```
Error: Connection refused - b3-timescaledb:5432
```

**Causas Poss√≠veis:**
1. Container TimescaleDB n√£o est√° rodando
2. Rede Docker incorreta
3. Credenciais incorretas

**Solu√ß√£o:**
```bash
# Verificar se container est√° rodando
docker ps | grep timescaledb

# Subir container se necess√°rio
cd /home/dellno/worksapace/b3-trading-platform
docker compose up -d b3-timescaledb

# Verificar rede
docker network ls | grep b3

# Testar conex√£o manualmente
docker exec -it b3-timescaledb psql -U b3trading_ts -d b3trading_market -c "SELECT 1;"
```

### Problema 4: "Dados j√° existem"

**Aviso:**
```
‚ö†Ô∏è PETR4 j√° tem 3994 registros em ohlcv_60min (2023-01-01 ‚Üí 2025-12-31)
Remover e reimportar? (s/N):
```

**Causas:**
- Importa√ß√£o anterior j√° foi feita

**Op√ß√µes:**
1. **Reimportar:** Digite `s` (remove dados antigos e importa novos)
2. **Pular:** Digite `n` (mant√©m dados existentes)

### Problema 5: "ModuleNotFoundError: asyncpg"

**Erro:**
```
ModuleNotFoundError: No module named 'asyncpg'
```

**Causa:**
- Depend√™ncias n√£o foram instaladas

**Solu√ß√£o:**
```bash
# Garantir que comando inclui instala√ß√£o de depend√™ncias
# O comando docker run DEVE ter:
bash -c "pip install -q asyncpg loguru && python3 /scripts/import_historical_data.py"
```

---

## üìú Hist√≥rico de Importa√ß√µes

### Importa√ß√£o 1: 28 de Janeiro de 2026

**Data:** 28/01/2026 √†s 00:58 UTC  
**Executor:** Script `import_historical_data.py` v1.0  
**Resultado:** ‚úÖ Sucesso

**Detalhes:**
- **Origem:** ProfitChart CSV (manual)
- **Pastas:** dados23e24 + dados26
- **Arquivos processados:** 157
- **Registros inseridos:** 775.259
- **Erros:** 0
- **Dura√ß√£o:** ~29 segundos
- **Performance:** ~26.733 registros/segundo

**Estat√≠sticas por Timeframe:**
- 15min: 338.847 registros (42 s√≠mbolos)
- 60min: 407.470 registros (57 s√≠mbolos)
- Di√°rio: 28.942 registros (58 s√≠mbolos)

**S√≠mbolos Priorit√°rios:**
- PETR4: 6.641 registros totais
- VALE3: 24.180 registros totais
- ITUB4: 16.588 registros totais
- BBDC4: 16.590 registros totais
- ABEV3: 16.600 registros totais

**Problemas Resolvidos:**
1. Parser CSV para arquivos Di√°rios (8 colunas vs 9)
2. Volume mount para acesso a pastas do host
3. Rede Docker para conex√£o com TimescaleDB

**Commit:** [pendente]

---

## üîÑ Atualiza√ß√µes Futuras

### Pr√≥ximas Importa√ß√µes

**Frequ√™ncia Recomendada:** Mensal (at√© dados ao vivo via API)

**Checklist para Pr√≥xima Importa√ß√£o:**
- [ ] Baixar dados atualizados do ProfitChart
- [ ] Colocar em pasta `dados{MES}{ANO}`
- [ ] Fazer backup do banco: `pg_dump > backup.sql`
- [ ] Executar script de importa√ß√£o
- [ ] Validar com queries de verifica√ß√£o
- [ ] Atualizar este documento com estat√≠sticas
- [ ] Commitar mudan√ßas no Git

### Melhorias Planejadas

1. **Script Incremental:**
   - Detectar novos arquivos automaticamente
   - Importar apenas dados novos (n√£o duplicar)

2. **Valida√ß√£o Autom√°tica:**
   - Rodar queries de valida√ß√£o ap√≥s importa√ß√£o
   - Alertar se houver gaps ou dados inconsistentes

3. **Logging Persistente:**
   - Salvar logs de importa√ß√£o em arquivo
   - Dashboard com hist√≥rico de importa√ß√µes

4. **API de Importa√ß√£o:**
   - Endpoint REST para trigger de importa√ß√£o
   - Upload de arquivos CSV via web

---

## üìû Refer√™ncias

- **Script:** [scripts/import_historical_data.py](../scripts/import_historical_data.py)
- **Documenta√ß√£o Geral:** [INSTRUCOES.md](../INSTRUCOES.md)
- **TimescaleDB Docs:** https://docs.timescale.com/
- **asyncpg Docs:** https://magicstack.github.io/asyncpg/

---

**√öltima Atualiza√ß√£o:** 28 de Janeiro de 2026  
**Autor:** Stock-IndiceDev Assistant  
**Status:** ‚úÖ Documenta√ß√£o Completa
